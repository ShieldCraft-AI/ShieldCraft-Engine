THE LITMUS ENGINE
A Deterministic Repository Review System for Decision Safety

Tagline (internal):
A senior reviewer that knows when not to speak.

0. Brutal Framing (Read This First)
Who this is for

Engineers inheriting unfamiliar or legacy systems

Tech leads deciding where to start safely

Architects assessing change risk before committing effort

Teams that want fewer mistakes, not more analysis

Who this is not for

Code style enforcement

Refactoring automation

“Find all issues” scanning

Junior-level static analysis replacement

Tools that maximize findings or activity

If your goal is speed through confidence, this is the wrong tool.
If your goal is speed through restraint, this is exactly the tool.

1. Why This Exists (Against Existing Tools)

Most repository tools fail in the same way:

They overproduce signals

They conflate presence with importance

They sound confident where evidence is thin

They encourage premature action

Linters, SAST tools, and static analyzers answer:

“What can I complain about?”

The Litmus Engine answers:

“What would be irresponsible to touch right now?”

This tool exists because false confidence is more dangerous than missing information.

2. Core Objective

Prevent harmful decisions in unfamiliar codebases by producing authoritative, restraint-oriented guidance grounded exclusively in observable evidence.

The engine must explicitly answer:

Where pressure can safely be applied

Where pressure must not be applied

What is currently unknowable

What looks risky but is not

Silence is a success state.

3. Proof of Seriousness (Non-Optional)

This repository must include the following from day one:

3.1 Deterministic Golden Snapshot

A sample repository (or reduced fixture)

A canonical output JSON

A canonical SHA-256 hash

“Running Litmus against commit X must always produce hash Y.”

3.2 Refusal Example

A documented case where the engine refuses to issue guidance, with explanation.

Example:

“Critical migration logic exists without tests. No safe change surface can be established.”

3.3 Misleading Signal Example

A documented case where a naïve tool would overreact — and Litmus explicitly does not.

4. Foundational Invariants (Hard Requirements)
4.1 Determinism (Absolute)

Identical input → identical output

No timestamps, randomness, environment leakage

Canonical traversal and ordering

Verifiable canonical hash emitted

4.2 Observable Signals Only

Allowed inputs:

Structure

Configuration

Tests

Dependencies

Versioning artifacts

Disallowed:

Guessing intent from names or comments

Sentiment or heuristic psychology

4.3 Restraint Is Mandatory

Findings are severity-gated

Low-risk repos may produce <1 page output

“Nothing notable” is valid

Output verbosity is bounded

5. Trust Contract (Explicit)

For every major conclusion, Litmus must include one of:

Why this conclusion is reliable

Why it is bounded

Why a less sophisticated tool would mislead here

This is not optional.
This is how trust is earned.

6. Intent Modeling (Bounded, Falsifiable)

Litmus does not infer motivation.
It classifies architectural posture.

6.1 Allowed Signals

Boundary enforcement

Governance strictness

Longevity handling (migrations, deprecations)

Investment asymmetry

6.2 Evolutionary Archetypes (Examples)

These must be concrete and memorable:

The Pressure Cooker
High change, low governance, tight coupling

The Museum
Stable, low change, high risk to disturb

The Construction Site
Actively evolving with guardrails

The Patchwork
Uneven maturity across domains

Each classification must include:

Evidence

Confidence level

Expiration conditions

7. Safe-to-Change Surface (Primary Artifact)
7.1 Definition

A permission model, not a score.

Answers:

“Where can pressure be applied right now without unacceptable risk?”

7.2 Required Properties

Explicit safe zones

Explicit no-touch zones

Expiration logic

Evidence references

7.3 Mandatory First Move

Litmus must always provide one of:

A safe first action

An explicit statement that no safe move exists

Absence of a safe surface is a valid finding.

8. What Not to Fix (First-Class Output)

Litmus must explicitly identify:

Benign issues

Areas that look risky but are currently stable

Optimizations that would be negative ROI

Each includes:

Why it is not an issue

When it would become one

This demonstrates senior restraint.

9. Uncertainty & Refusal Model
9.1 Visible Uncertainty

Uncertainty is:

Localized

Explained

Calm

9.2 Mandatory Refusal Conditions

Litmus must refuse when:

Critical paths lack tests or contracts

Blast radius cannot be bounded

Configuration is contradictory

Refusal is a successful outcome.

10. Multi-Language as Blast-Radius Control

One primary language per scan

Secondary languages analyzed structurally only

Semantic analysis never guesses across boundaries

This prevents false authority and overreach.

11. Output Contract (Human-Grade)
11.1 Executive Summary (≤1 page)

Must answer:

Is it safe to act?

Where?

Where not?

What is unknowable?

No vanity metrics.

11.2 Decision Artifacts

Safe-to-Change Surface

No-Touch Zones

Misleading Signals

First Recommended Action

11.3 Evidence Appendix

Evidence references only

No speculative commentary

12. Tone & Voice Constraints

Calm

Direct

Senior

No hype

No AI voice

Reads like a VP-level technical memo

13. Deterministic Silence Requirement

Maximum verbosity thresholds

Severity-gated output volume

Explicit “Nothing notable” verdicts allowed

Brevity is enforced, not emergent.

14. Final Litmus Test (Non-Negotiable)

A senior engineer reading the output should think:

“This is exactly what I would have said —
and I trust it because it knows when not to speak.”

If this fails, the implementation is incorrect.

15. Why This Is Unreasonably Good

It prevents damage instead of producing noise

It encodes senior judgment, not heuristics

It refuses when evidence is insufficient

It is deterministic, auditable, and calm

It optimizes for decision safety, not activity